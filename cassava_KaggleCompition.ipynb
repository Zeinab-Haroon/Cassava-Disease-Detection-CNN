{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Convnet_project1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d31074ec9ad44cf8a249505fd17d822a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_adbb9cee23c34f5abab05ceff18b5cf0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b230e4ad10243caa43919f67a54a93a",
              "IPY_MODEL_1249857d35e24801853c88ca4aadc7df"
            ]
          }
        },
        "adbb9cee23c34f5abab05ceff18b5cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b230e4ad10243caa43919f67a54a93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e57484ca36964707908924250714c1ed",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c95ba740214142e29aab7515e2a2c562"
          }
        },
        "1249857d35e24801853c88ca4aadc7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_360d2b2d6519414ab6a9f69926aa10c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 177MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_569526a0d5094bf288c827e14c200447"
          }
        },
        "e57484ca36964707908924250714c1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c95ba740214142e29aab7515e2a2c562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "360d2b2d6519414ab6a9f69926aa10c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "569526a0d5094bf288c827e14c200447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em0qLRPqjZ9e",
        "colab_type": "text"
      },
      "source": [
        "### Conputer vision project: Cassava disease detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ybsiBZkwcy",
        "colab_type": "code",
        "outputId": "b4cdae18-fa2f-4935-f59a-c6f344acf096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ4CxOdhk7L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp \"/content/drive/My Drive/ammi-2020-convnets.zip\" /content\n",
        "# !unzip \"ammi-2020-convnets.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t6K5yr55GUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"zeinabalmahdi\",\"key\":\"e990b70a4fb3a04230f6ee1ef1c66be0\"}' > ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPs7ABD95ukb",
        "colab_type": "code",
        "outputId": "33daaaae-6ce9-452a-954c-a929d547d15f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "!kaggle competitions download -c cassava-disease"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading extraimages.zip to /content\n",
            " 99% 1.03G/1.04G [00:18<00:00, 60.2MB/s]\n",
            "100% 1.04G/1.04G [00:18<00:00, 60.3MB/s]\n",
            "Downloading test.zip to /content\n",
            " 95% 489M/515M [00:04<00:00, 117MB/s]\n",
            "100% 515M/515M [00:04<00:00, 110MB/s]\n",
            "Downloading train.zip to /content\n",
            " 99% 771M/777M [00:10<00:00, 104MB/s] \n",
            "100% 777M/777M [00:11<00:00, 74.0MB/s]\n",
            "Downloading random.txt to /content\n",
            "  0% 0.00/645k [00:00<?, ?B/s]\n",
            "100% 645k/645k [00:00<00:00, 90.1MB/s]\n",
            "Downloading sample_submission_file.csv to /content\n",
            "  0% 0.00/83.8k [00:00<?, ?B/s]\n",
            "100% 83.8k/83.8k [00:00<00:00, 83.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDhT67jW5-No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip -n train.zip\n",
        "!unzip -n test.zip\n",
        "!unzip -n extraimages.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "linWuIXNPdRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install albumenatations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Ny6mxcjZ9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### import packages \n",
        "import torch \n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms,datasets, models\n",
        "from skimage import io , transform\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import os\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt \n",
        "import cv2 \n",
        "from torch import optim\n",
        "\n",
        "import warnings \n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "\n",
        "from albumentations import (\n",
        "    HorizontalFlip,RandomRotate90,CenterCrop,Compose,VerticalFlip,Rotate,RandomSizedCrop,Normalize,Resize\n",
        ")\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "x = {name : idx for idx,name in enumerate(os.listdir(\"train\"))}\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZyRuJUDQFtY",
        "colab_type": "code",
        "outputId": "a1bb9893-90ab-4ec8-aea0-334629efd104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cbb': 1, 'cbsd': 3, 'cgm': 0, 'cmd': 2, 'healthy': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz1UCIU5jZ9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #### Set deterministic random operation for the notebook.....\n",
        "# def setup_seed(seed=101):\n",
        "#     torch.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "#     np.random.seed(seed)\n",
        "#     random.seed(seed)\n",
        "#     torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTd6FKpHQ9BK",
        "colab_type": "code",
        "outputId": "714a8855-3d7d-4f6e-b9eb-7fdb2993b1d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(os.listdir(\"extraimages\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSYlaqqJjZ9p",
        "colab_type": "text"
      },
      "source": [
        "### Exploratory analysis of data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UA_iEXvjZ9q",
        "colab_type": "code",
        "outputId": "9c8cc248-3abb-498a-d213-6001f56dc0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#### checking the entire images in the folders \n",
        "#########\n",
        "\n",
        "Total = {}\n",
        "for file in os.listdir(\"train\"):\n",
        "    Total[file] = len(os.listdir(os.path.join(\"train\",file)))\n",
        "print(f\"The total images in individual class: {Total} \\n\")\n",
        "\n",
        "extra = len(os.listdir(\"extraimages\"))\n",
        "print(\"The total images in extraimages set: \",str(extra),\"\\n\")\n",
        "print(\"The entire images in the test: \",str(len(os.listdir(\"test\"))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total images in individual class: {'cgm': 773, 'cbb': 466, 'cmd': 2658, 'cbsd': 1443, 'healthy': 316} \n",
            "\n",
            "The total images in extraimages set:  12596 \n",
            "\n",
            "The entire images in the test:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBUlJ7Q8jZ9s",
        "colab_type": "code",
        "outputId": "ddb79dd5-93d4-4282-e8e9-a3c79ac6e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.listdir(\"train\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cgm', 'cbb', 'cmd', 'cbsd', 'healthy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkXmEEQmjZ9v",
        "colab_type": "code",
        "outputId": "4bc31183-2e77-42ce-b173-649627fa18ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#### Visualization of images \n",
        "\n",
        "numel = np.arange(len(Total.keys()))\n",
        "conditions = Total.values()\n",
        "labels = Total.keys()\n",
        "\n",
        "\n",
        "fig ,ax = plt.subplots()\n",
        "#### Plot the level of images \n",
        "\n",
        "ax.barh(numel,conditions)\n",
        "ax.set_yticks(numel)\n",
        "ax.set_yticklabels(labels)\n",
        "ax.set_ylabel(\"Diseases\")\n",
        "ax.set_title(\"Type of diseases\")\n",
        "ax.set_xlabel(\"Total number of each diseases\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 407,
              "height": 277
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwF0w8XXjZ9y",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the datasets into train and validation sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye4xZYvzjZ9z",
        "colab_type": "code",
        "outputId": "4310c2ae-c9bc-4a73-edcb-02cd2bf7b2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#### Split the train set into train and validation set \n",
        "import random\n",
        "class2label = {label : idx for idx, label in enumerate(os.listdir(\"train\"))}\n",
        "\n",
        "#### Get the total images, train and validation. \n",
        "total_images = {}\n",
        "train_images = {}\n",
        "valid_images = {}\n",
        "\n",
        "train_path = \"train\"\n",
        "for label in os.listdir(train_path):\n",
        "    eachTotal = len(os.listdir(os.path.join(train_path,label)))\n",
        "    for imgs in os.listdir(os.path.join(train_path,label)):\n",
        "        img = os.path.join(train_path,label,imgs) ##an image \n",
        "        total_images[img] = class2label[label]\n",
        "    valid_sets = random.sample(os.listdir(os.path.join(train_path,label)),int(eachTotal * 0.15))\n",
        "    \n",
        "    for img in valid_sets:\n",
        "        img_ = os.path.join(train_path,label,img)\n",
        "        valid_images[img_] = class2label[label]\n",
        "    for imgs in os.listdir(os.path.join(train_path,label)):\n",
        "        if imgs not in valid_sets:\n",
        "            im_ = os.path.join(train_path,label,imgs)\n",
        "            train_images[im_] = class2label[label]\n",
        "\n",
        "print(f\"The total training set: {len(total_images)} \\n\")        \n",
        "print(f\"The total training sets: {len(train_images)} \\n\")\n",
        "print(f\"The total validation set: {len(valid_images)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total training set: 5656 \n",
            "\n",
            "The total training sets: 4811 \n",
            "\n",
            "The total validation set: 845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Z3ek84jZ93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from glob import glob \n",
        "# #### set all the path into a dictionary \n",
        "# path = {\"train\": \"competitions/ammi-2020-convnets/train/train\",\n",
        "#         \"test\": \"competitions/ammi-2020-convnets/test/test/\",\n",
        "#         \"extraimages\": \"competitions/ammi-2020-convnets/extraimages/extraimages/ \"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxCL4e3ljZ95",
        "colab_type": "text"
      },
      "source": [
        "### Loading the datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulzNJpP-jZ95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Now we have to build class for the data. \n",
        "\n",
        "class CassavaDisease(Dataset):\n",
        "    \n",
        "    \"\"\"\n",
        "    Class object for loading datasets \n",
        "    Arguments: Takes the path to the datasets. \n",
        "    Transform image \n",
        "    mode: Train / Test \n",
        "    \n",
        "    Return:\n",
        "        Load the datasets from the disk. \n",
        "    \"\"\"\n",
        "    def __init__(self,Datasets,transform = None , mode = False,labels = class2label):\n",
        "        \n",
        "        self.dataset = Datasets  ### set the path to the image \n",
        "        self.transform = transform    ### transform the image \n",
        "        self.mode = mode\n",
        "        self.label2class = {label : Class for Class,label in class2label.items()}\n",
        "        \n",
        "        if self.mode is \"Train\" or self.mode is \"Valid\":\n",
        "            \n",
        "            self.images , self.labels = [] , []\n",
        "            \n",
        "            for image, label in self.dataset.items():\n",
        "                self.images.append(image)\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "        images = self.images[idx]\n",
        "        labels = self.labels[idx]\n",
        "        images = cv2.imread(images)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            images = self.transform(image =images)[\"image\"]\n",
        "\n",
        "        \"\"\"\n",
        "        Return:\n",
        "            image and label of the respective folders\n",
        "        \"\"\"\n",
        "\n",
        "        return images , labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x51Mp_hjZ97",
        "colab_type": "text"
      },
      "source": [
        "### Data augmentation stage: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVJE89W1jZ98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_aug():\n",
        "    return Compose([\n",
        "        Resize(256,256),\n",
        "        HorizontalFlip(p=0.2),\n",
        "        VerticalFlip(),\n",
        "        RandomRotate90(),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225],max_pixel_value=225,always_apply=True),\n",
        "        ToTensor()\n",
        "    ])\n",
        "\n",
        "def test_aug():\n",
        "    return Compose([\n",
        "        Resize(224,224),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225],max_pixel_value=225,always_apply=True),\n",
        "        ToTensor()\n",
        "    ])\n",
        "if __name__ == \"__main__\":\n",
        "    train_aug = train_aug()\n",
        "    test_aug = test_aug()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNmMX7pjZ9_",
        "colab_type": "text"
      },
      "source": [
        "### Loading the datasets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_05ruUQzjZ-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Access the trainset and validation sets \n",
        "trainset = CassavaDisease(train_images,mode = \"Train\",transform= train_aug)\n",
        "validset = CassavaDisease(valid_images,mode = \"Valid\",transform = test_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXKMlze5jZ-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = DataLoader(trainset,batch_size= 32,shuffle=True)\n",
        "testloader = DataLoader(validset,batch_size= 32 , shuffle= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCFSKHiHjZ-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs , labs = next(iter(trainloader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXw1R-0QjZ-J",
        "colab_type": "text"
      },
      "source": [
        "### Model formulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCBO7BajZ-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### setting the device to cuda:\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHrreQeEjZ-L",
        "colab_type": "code",
        "outputId": "901fae8e-21af-4158-ad85-0f9e5632fce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d31074ec9ad44cf8a249505fd17d822a",
            "adbb9cee23c34f5abab05ceff18b5cf0",
            "2b230e4ad10243caa43919f67a54a93a",
            "1249857d35e24801853c88ca4aadc7df",
            "e57484ca36964707908924250714c1ed",
            "c95ba740214142e29aab7515e2a2c562",
            "360d2b2d6519414ab6a9f69926aa10c2",
            "569526a0d5094bf288c827e14c200447"
          ]
        }
      },
      "source": [
        "##### In the first we will pretraied model \n",
        "model = models.resnet50(pretrained = True)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d31074ec9ad44cf8a249505fd17d822a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy96IYmJkvQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc = torch.nn.Linear(in_features=2048, out_features=5, bias=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UygIWF-VjZ-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False \n",
        "    \n",
        "from collections import OrderedDict\n",
        "from torch import nn \n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    (\"fc1\",nn.Linear(model.fc.in_features,128)),\n",
        "    (\"ReLU\",nn.ReLU(inplace=True)),\n",
        "    (\"dropout\",nn.Dropout(p=0.2)),\n",
        "    (\"fc2\",nn.Linear(128,64)),\n",
        "    (\"ReLU\",nn.ReLU()),\n",
        "    (\"fc3\",nn.Linear(64,5))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz0t0MqljZ-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Append the last layer of the classifier. \n",
        "#model.fc = classifier\n",
        "model.fc = classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ4uqROIjZ-S",
        "colab_type": "code",
        "outputId": "304da544-5ea6-4532-8db0-f6bd1c1e6170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.fc.parameters()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f51e00c0e08>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9xR6pzejZ-U",
        "colab_type": "code",
        "outputId": "74e9729c-b7e6-471a-b5d9-875422d67fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(trainloader.dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScQaX4t2jZ-W",
        "colab_type": "text"
      },
      "source": [
        "### Build the training loop for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUq-WuYjZ-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### time the number epoch \n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "#### set the criterion and optimizers \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "Optim = optim.Adam(model.parameters(), lr = 0.001)\n",
        "step_size = 30\n",
        "scheduler = lr_scheduler.StepLR(Optim,step_size=step_size,gamma=0.1)\n",
        "#### define the training loop \n",
        "\n",
        "def train(model,trainloader,criterion,optim,num_epoch,scheduler):\n",
        "    \n",
        "    \n",
        "    model = model.to(device)\n",
        "    trainloss = []\n",
        "    \n",
        "    model.train()\n",
        "    i = 0\n",
        "    for epoch in range(num_epoch):\n",
        "        ###initialize the training loss at every epoch  \n",
        "        correct_number = 0\n",
        "        losstrain = 0 \n",
        "        scheduler.step()    ##### decay the learning after 30 epoch \n",
        "        for  images,labels in trainloader:\n",
        "            #### set the images and labels to device \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            #### make predictions\n",
        "            preds = model(images)\n",
        "            optim.zero_grad() ### not to cumulate the gradient\n",
        "            loss = criterion(preds,labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            ##### sum the loss \n",
        "            losstrain += loss.detach().item() * images.detach().size(0)\n",
        "\n",
        "            correct_number += (preds.max(1)[1]==labels).sum()\n",
        "\n",
        "        accuracy = 100.0 * correct_number / len(trainloader.dataset)\n",
        "        Loss = losstrain / len(trainloader)\n",
        "        trainloss.append(Loss)    ##store all the training loss  \n",
        "        \n",
        "        print(\"After 10 epoch of training\")\n",
        "        print(f\"Training loss: {Loss : .2f} , Accuracy: {accuracy:.2f}  after {epoch + 1} epoch\")                 \n",
        "        \n",
        "def valid(model,testloader):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        #### set the model eval mode\n",
        "        model.eval()\n",
        "        valid_acc = 0 \n",
        "        for images , labels in testloader:\n",
        "            \n",
        "            ### set to the gpu \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            ### predict the image\n",
        "            preds = model(images)\n",
        "            #### pick the maximum index of value \n",
        "            preds = preds.detach().argmax(dim=1,keepdim=True)\n",
        "            labels = labels.detach()\n",
        "            #correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "            valid_acc += preds.eq(labels.view_as(preds)).sum().item()\n",
        "            \n",
        "        print(f\"Validation accuracy : {(valid_acc/len(testloader.dataset)) * 100 :.0f}%\")   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzMxqbx1jZ-Y",
        "colab_type": "code",
        "outputId": "8a2a080a-f567-4985-e6b6-8f010b2268c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "###### execute the loop for each loop\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    #### setting the training loop and test loop \n",
        "    train(model= model, trainloader=trainloader,criterion=criterion,optim=Optim,num_epoch=40,scheduler= scheduler)\n",
        "    #### \n",
        "    valid(model=model,testloader=testloader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After 10 epoch of training\n",
            "Training loss:  34.89 , Accuracy: 60.72  after 1 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  29.98 , Accuracy: 66.47  after 2 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  28.21 , Accuracy: 69.38  after 3 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  25.18 , Accuracy: 72.77  after 4 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  24.20 , Accuracy: 74.35  after 5 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  22.56 , Accuracy: 75.45  after 6 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  21.26 , Accuracy: 77.49  after 7 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  20.07 , Accuracy: 78.65  after 8 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  19.72 , Accuracy: 78.82  after 9 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  19.79 , Accuracy: 78.51  after 10 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  18.33 , Accuracy: 80.57  after 11 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  17.69 , Accuracy: 80.98  after 12 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  17.79 , Accuracy: 80.75  after 13 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  17.61 , Accuracy: 80.77  after 14 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  16.58 , Accuracy: 82.89  after 15 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  16.34 , Accuracy: 82.31  after 16 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  15.97 , Accuracy: 82.66  after 17 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  15.74 , Accuracy: 83.50  after 18 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  15.63 , Accuracy: 83.08  after 19 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  14.83 , Accuracy: 84.43  after 20 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  15.57 , Accuracy: 83.04  after 21 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  14.87 , Accuracy: 84.95  after 22 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  14.75 , Accuracy: 83.97  after 23 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  13.96 , Accuracy: 85.24  after 24 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  13.16 , Accuracy: 86.28  after 25 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  13.00 , Accuracy: 86.39  after 26 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  12.72 , Accuracy: 86.70  after 27 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  13.28 , Accuracy: 86.03  after 28 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  12.69 , Accuracy: 87.11  after 29 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  9.47 , Accuracy: 90.13  after 30 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  8.29 , Accuracy: 91.60  after 31 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  7.63 , Accuracy: 92.21  after 32 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  7.53 , Accuracy: 92.58  after 33 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  7.38 , Accuracy: 92.70  after 34 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  7.08 , Accuracy: 93.22  after 35 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  6.75 , Accuracy: 93.12  after 36 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  6.56 , Accuracy: 93.47  after 37 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  6.19 , Accuracy: 94.03  after 38 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  6.20 , Accuracy: 93.87  after 39 epoch\n",
            "After 10 epoch of training\n",
            "Training loss:  6.13 , Accuracy: 94.10  after 40 epoch\n",
            "Validation accuracy : 82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MumB043Fxvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid(model=model,test`loader=testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}